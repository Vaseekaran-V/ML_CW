{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.catboost\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.DataPreprocessPipeline import DataPreprocessPipeline\n",
    "preprocessor = DataPreprocessPipeline(num_lags=3, rolling_window_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../../data/training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>item_dept</th>\n",
       "      <th>item_qty</th>\n",
       "      <th>net_sales</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>invoice_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/1/2021</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>16620</td>\n",
       "      <td>1475459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/1/2021</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>2.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>32365</td>\n",
       "      <td>1475459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/1/2021</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>31349</td>\n",
       "      <td>1475459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/1/2021</td>\n",
       "      <td>Household</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>1266</td>\n",
       "      <td>1475475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/1/2021</td>\n",
       "      <td>Household</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>114920</td>\n",
       "      <td>1475475.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_id  item_dept  item_qty  net_sales store    item  invoice_num\n",
       "0  11/1/2021    Grocery       1.0      160.0   XYZ   16620    1475459.0\n",
       "1  11/1/2021    Grocery       2.0      480.0   XYZ   32365    1475459.0\n",
       "2  11/1/2021    Grocery       1.0      127.0   XYZ   31349    1475459.0\n",
       "3  11/1/2021  Household       2.0      110.0   XYZ    1266    1475475.0\n",
       "4  11/1/2021  Household       1.0      150.0   XYZ  114920    1475475.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>item_dept</th>\n",
       "      <th>store</th>\n",
       "      <th>item_qty</th>\n",
       "      <th>net_sales</th>\n",
       "      <th>lag_item_qty_1</th>\n",
       "      <th>lag_item_qty_2</th>\n",
       "      <th>lag_item_qty_3</th>\n",
       "      <th>rolling_mean_item_qty_3</th>\n",
       "      <th>rolling_std_item_qty_3</th>\n",
       "      <th>...</th>\n",
       "      <th>expanding_min_net_sales</th>\n",
       "      <th>expanding_max_net_sales</th>\n",
       "      <th>diff_net_sales</th>\n",
       "      <th>diff_net_sales_7</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>Is_Holiday</th>\n",
       "      <th>store_XYZ</th>\n",
       "      <th>item_dept_Grocery</th>\n",
       "      <th>item_dept_Household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>ABC</td>\n",
       "      <td>974.000</td>\n",
       "      <td>246984.68200</td>\n",
       "      <td>937.000</td>\n",
       "      <td>884.000</td>\n",
       "      <td>991.000</td>\n",
       "      <td>937.333333</td>\n",
       "      <td>53.500779</td>\n",
       "      <td>...</td>\n",
       "      <td>199145.596010</td>\n",
       "      <td>2.779048e+05</td>\n",
       "      <td>-23294.307000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>677.000</td>\n",
       "      <td>201386.08100</td>\n",
       "      <td>1043.000</td>\n",
       "      <td>1086.000</td>\n",
       "      <td>910.000</td>\n",
       "      <td>1013.000000</td>\n",
       "      <td>91.755109</td>\n",
       "      <td>...</td>\n",
       "      <td>187931.769020</td>\n",
       "      <td>2.899930e+05</td>\n",
       "      <td>27566.920000</td>\n",
       "      <td>-102.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>ABC</td>\n",
       "      <td>2326.638</td>\n",
       "      <td>438841.43801</td>\n",
       "      <td>2646.820</td>\n",
       "      <td>2614.006</td>\n",
       "      <td>2654.582</td>\n",
       "      <td>2638.469333</td>\n",
       "      <td>21.538411</td>\n",
       "      <td>...</td>\n",
       "      <td>397946.965024</td>\n",
       "      <td>5.822066e+05</td>\n",
       "      <td>-43148.157030</td>\n",
       "      <td>-33.761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>2879.414</td>\n",
       "      <td>498037.79100</td>\n",
       "      <td>3608.962</td>\n",
       "      <td>3625.864</td>\n",
       "      <td>3287.828</td>\n",
       "      <td>3507.551333</td>\n",
       "      <td>190.473559</td>\n",
       "      <td>...</td>\n",
       "      <td>491450.723000</td>\n",
       "      <td>6.616550e+05</td>\n",
       "      <td>38798.438006</td>\n",
       "      <td>-107.646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>Household</td>\n",
       "      <td>ABC</td>\n",
       "      <td>883.000</td>\n",
       "      <td>240294.89201</td>\n",
       "      <td>998.000</td>\n",
       "      <td>1152.000</td>\n",
       "      <td>986.000</td>\n",
       "      <td>1045.333333</td>\n",
       "      <td>92.570694</td>\n",
       "      <td>...</td>\n",
       "      <td>209100.513996</td>\n",
       "      <td>2.920205e+05</td>\n",
       "      <td>-50544.119984</td>\n",
       "      <td>-160.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>791.000</td>\n",
       "      <td>179122.36501</td>\n",
       "      <td>1048.000</td>\n",
       "      <td>1255.000</td>\n",
       "      <td>1336.000</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>148.522726</td>\n",
       "      <td>...</td>\n",
       "      <td>149946.090000</td>\n",
       "      <td>5.130570e+05</td>\n",
       "      <td>-97559.236000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>ABC</td>\n",
       "      <td>2603.874</td>\n",
       "      <td>542643.93100</td>\n",
       "      <td>2869.215</td>\n",
       "      <td>2587.436</td>\n",
       "      <td>2358.758</td>\n",
       "      <td>2605.136333</td>\n",
       "      <td>255.688411</td>\n",
       "      <td>...</td>\n",
       "      <td>367440.183000</td>\n",
       "      <td>2.035445e+06</td>\n",
       "      <td>33708.435960</td>\n",
       "      <td>286.094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>2996.909</td>\n",
       "      <td>563043.73400</td>\n",
       "      <td>4040.207</td>\n",
       "      <td>3539.002</td>\n",
       "      <td>3162.792</td>\n",
       "      <td>3580.667000</td>\n",
       "      <td>440.188880</td>\n",
       "      <td>...</td>\n",
       "      <td>443513.481000</td>\n",
       "      <td>1.161787e+06</td>\n",
       "      <td>89212.836000</td>\n",
       "      <td>434.602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>Household</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1115.000</td>\n",
       "      <td>314800.26999</td>\n",
       "      <td>1170.000</td>\n",
       "      <td>1236.000</td>\n",
       "      <td>1062.000</td>\n",
       "      <td>1156.000000</td>\n",
       "      <td>87.840765</td>\n",
       "      <td>...</td>\n",
       "      <td>181968.999000</td>\n",
       "      <td>4.518945e+05</td>\n",
       "      <td>-26337.569910</td>\n",
       "      <td>180.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>Household</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>1141.000</td>\n",
       "      <td>269010.67500</td>\n",
       "      <td>1298.000</td>\n",
       "      <td>1205.000</td>\n",
       "      <td>1051.000</td>\n",
       "      <td>1184.666667</td>\n",
       "      <td>124.749081</td>\n",
       "      <td>...</td>\n",
       "      <td>187888.597090</td>\n",
       "      <td>3.829678e+05</td>\n",
       "      <td>1473.762000</td>\n",
       "      <td>195.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_id  item_dept store  item_qty     net_sales  lag_item_qty_1  \\\n",
       "42  2021-11-08  Beverages   ABC   974.000  246984.68200         937.000   \n",
       "43  2021-11-08  Beverages   XYZ   677.000  201386.08100        1043.000   \n",
       "44  2021-11-08    Grocery   ABC  2326.638  438841.43801        2646.820   \n",
       "45  2021-11-08    Grocery   XYZ  2879.414  498037.79100        3608.962   \n",
       "46  2021-11-08  Household   ABC   883.000  240294.89201         998.000   \n",
       "..         ...        ...   ...       ...           ...             ...   \n",
       "547 2022-01-31  Beverages   XYZ   791.000  179122.36501        1048.000   \n",
       "548 2022-01-31    Grocery   ABC  2603.874  542643.93100        2869.215   \n",
       "549 2022-01-31    Grocery   XYZ  2996.909  563043.73400        4040.207   \n",
       "550 2022-01-31  Household   ABC  1115.000  314800.26999        1170.000   \n",
       "551 2022-01-31  Household   XYZ  1141.000  269010.67500        1298.000   \n",
       "\n",
       "     lag_item_qty_2  lag_item_qty_3  rolling_mean_item_qty_3  \\\n",
       "42          884.000         991.000               937.333333   \n",
       "43         1086.000         910.000              1013.000000   \n",
       "44         2614.006        2654.582              2638.469333   \n",
       "45         3625.864        3287.828              3507.551333   \n",
       "46         1152.000         986.000              1045.333333   \n",
       "..              ...             ...                      ...   \n",
       "547        1255.000        1336.000              1213.000000   \n",
       "548        2587.436        2358.758              2605.136333   \n",
       "549        3539.002        3162.792              3580.667000   \n",
       "550        1236.000        1062.000              1156.000000   \n",
       "551        1205.000        1051.000              1184.666667   \n",
       "\n",
       "     rolling_std_item_qty_3  ...  expanding_min_net_sales  \\\n",
       "42                53.500779  ...            199145.596010   \n",
       "43                91.755109  ...            187931.769020   \n",
       "44                21.538411  ...            397946.965024   \n",
       "45               190.473559  ...            491450.723000   \n",
       "46                92.570694  ...            209100.513996   \n",
       "..                      ...  ...                      ...   \n",
       "547              148.522726  ...            149946.090000   \n",
       "548              255.688411  ...            367440.183000   \n",
       "549              440.188880  ...            443513.481000   \n",
       "550               87.840765  ...            181968.999000   \n",
       "551              124.749081  ...            187888.597090   \n",
       "\n",
       "     expanding_max_net_sales  diff_net_sales  diff_net_sales_7  day_of_week  \\\n",
       "42              2.779048e+05   -23294.307000            57.000            0   \n",
       "43              2.899930e+05    27566.920000          -102.000            0   \n",
       "44              5.822066e+05   -43148.157030           -33.761            0   \n",
       "45              6.616550e+05    38798.438006          -107.646            0   \n",
       "46              2.920205e+05   -50544.119984          -160.000            0   \n",
       "..                       ...             ...               ...          ...   \n",
       "547             5.130570e+05   -97559.236000            22.000            0   \n",
       "548             2.035445e+06    33708.435960           286.094            0   \n",
       "549             1.161787e+06    89212.836000           434.602            0   \n",
       "550             4.518945e+05   -26337.569910           180.000            0   \n",
       "551             3.829678e+05     1473.762000           195.000            0   \n",
       "\n",
       "     isWeekend  Is_Holiday  store_XYZ  item_dept_Grocery  item_dept_Household  \n",
       "42           0           0        0.0                0.0                  0.0  \n",
       "43           0           0        1.0                0.0                  0.0  \n",
       "44           0           0        0.0                1.0                  0.0  \n",
       "45           0           0        1.0                1.0                  0.0  \n",
       "46           0           0        0.0                0.0                  1.0  \n",
       "..         ...         ...        ...                ...                  ...  \n",
       "547          0           0        1.0                0.0                  0.0  \n",
       "548          0           0        0.0                1.0                  0.0  \n",
       "549          0           0        1.0                1.0                  0.0  \n",
       "550          0           0        0.0                0.0                  1.0  \n",
       "551          0           0        1.0                0.0                  1.0  \n",
       "\n",
       "[510 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_preprocessed = preprocessor.transform(train_df)\n",
    "train_df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_helpers import create_training_testing\n",
    "train_dict, valid_dict = create_training_testing(train_df_preprocessed, test_date_start='2022-01-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_dict['train_features']\n",
    "train_y_sales = train_dict['train_net_sales']\n",
    "train_y_item_qty = train_dict['train_item_qty']\n",
    "\n",
    "val_X = valid_dict['train_features']\n",
    "val_y_sales = valid_dict['train_net_sales']\n",
    "val_y_item_qty = valid_dict['train_item_qty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SalesItemQtyModel import SalesItemQtyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    model_sales = CatBoostRegressor(**params, verbose = 0)\n",
    "    model_item_qty = CatBoostRegressor(**params, verbose = 0)\n",
    "\n",
    "    sales_item_qty_model = SalesItemQtyModel(model_sales = model_sales, model_item_qty=model_item_qty)\n",
    "    sales_item_qty_model.fit(train_X, train_y_sales, train_y_item_qty)\n",
    "\n",
    "    score_val_sales = sales_item_qty_model.score_sales(val_X, val_y_sales)\n",
    "    score_val_item_qty = sales_item_qty_model.score_item_qty(val_X, val_y_item_qty)\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"val_sales_MAPE\", score_val_sales)\n",
    "        mlflow.log_metric(\"val_item_qty_MAPE\", score_val_item_qty)\n",
    "        mlflow.catboost.log_model(model_sales, \"model_sales\")\n",
    "        mlflow.catboost.log_model(model_item_qty, \"model_item_qty\")\n",
    "\n",
    "    # Objective is to minimize the average of the two MSEs\n",
    "    return {'loss': (score_val_sales + score_val_item_qty) / 2, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for Hyperopt\n",
    "search_space = {\n",
    "    'depth': hp.quniform('depth', 4, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'iterations': scope.int(hp.quniform('iterations', 100, 1000, 50)),\n",
    "    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1e-5, 100),\n",
    "    'border_count': scope.int(hp.quniform('border_count', 32, 255, 1)),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0, 1),\n",
    "    'random_strength': hp.uniform('random_strength', 1e-9, 10),\n",
    "    'one_hot_max_size': scope.int(hp.quniform('one_hot_max_size', 2, 255, 1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:14 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:17 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:11<18:39, 11.31s/trial, best loss: 0.1509964447667711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:21 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:18<14:03,  8.61s/trial, best loss: 0.1509964447667711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:24<12:34,  7.77s/trial, best loss: 0.14665684322659833]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:34 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:37 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:31<12:02,  7.53s/trial, best loss: 0.1368103090361735] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:38<11:06,  7.02s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:49 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:53 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:47<12:10,  7.77s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:09:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:09:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:53<11:16,  7.28s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:10:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:10:31 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:26<23:30, 15.33s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:10:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:10:37 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:32<18:46, 12.37s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:10:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:10:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:39<16:04, 10.72s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:10:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:10:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:54<17:52, 12.05s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:11:19 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:11:22 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [02:16<22:22, 15.26s/trial, best loss: 0.13498364655074835]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:11:26 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:11:29 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [02:23<18:35, 12.82s/trial, best loss: 0.12704882105741988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:11:33 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:11:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [02:30<15:31, 10.83s/trial, best loss: 0.12704882105741988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:11:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:11:41 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [02:35<13:11,  9.31s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:11:49 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:11:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [02:46<13:45,  9.83s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:11:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:11:58 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [02:52<11:55,  8.62s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:58<10:32,  7.72s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [03:03<09:32,  7.06s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:13 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:16 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [03:10<09:07,  6.84s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:26 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [03:22<11:20,  8.62s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:34 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [03:30<10:49,  8.33s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [03:36<09:37,  7.50s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:45 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [03:42<09:00,  7.11s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:53 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [03:47<08:06,  6.49s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:12:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:12:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [03:53<07:49,  6.34s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [04:01<08:21,  6.87s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:10 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:13 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [04:07<07:53,  6.58s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:16 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:19 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [04:13<07:31,  6.36s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:22 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:24 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [04:19<07:13,  6.19s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:31 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [04:25<07:07,  6.20s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:34 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:37 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [04:31<06:55,  6.11s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [04:37<06:52,  6.16s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:49 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [04:43<06:43,  6.11s/trial, best loss: 0.11916991020592088]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:13:55 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [04:49<06:36,  6.11s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:13:58 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [04:55<06:25,  6.03s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [05:01<06:16,  5.98s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:10 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:12 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [05:06<06:03,  5.87s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:16 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:18 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [05:13<06:04,  5.98s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:22 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:24 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [05:18<05:53,  5.90s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [05:24<05:47,  5.88s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:33 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [05:30<05:32,  5.74s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [05:36<05:43,  6.02s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:49 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [05:43<05:46,  6.20s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:54 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [05:48<05:26,  5.93s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:14:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:14:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [05:53<05:08,  5.72s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:03 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:05 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [05:59<05:01,  5.69s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:11 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [06:06<05:09,  5.95s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:20 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [06:17<06:24,  7.53s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [06:24<06:14,  7.49s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:38 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [06:32<06:09,  7.54s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:41 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [06:37<05:33,  6.96s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:51 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [06:45<05:41,  7.26s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:15:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:15:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [06:53<05:41,  7.41s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:16:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [07:03<06:08,  8.18s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:12 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:16:14 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [07:09<05:24,  7.38s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:18 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:16:21 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [07:15<05:04,  7.08s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:24 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:16:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [07:21<04:46,  6.83s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:32 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:16:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [07:29<04:50,  7.09s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:16:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [07:36<04:41,  7.04s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:16:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:00 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [07:54<06:40, 10.28s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:03 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:06 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [08:00<05:45,  9.10s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:11 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [08:05<04:54,  7.96s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:15 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:17 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [08:11<04:21,  7.26s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:34 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [08:30<06:21, 10.91s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:42 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [08:36<05:15,  9.27s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:45 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:47 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [08:41<04:25,  8.06s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [08:46<03:51,  7.23s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:17:55 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:17:58 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [08:52<03:26,  6.66s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [08:58<03:16,  6.55s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [09:04<03:01,  6.27s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:12 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:15 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [09:09<02:46,  5.96s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:18 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:20 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [09:14<02:34,  5.73s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:24 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:26 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [09:20<02:32,  5.86s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:29 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:31 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [09:25<02:21,  5.67s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:35 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:38 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [09:32<02:20,  5.86s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:41 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [09:37<02:10,  5.69s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:48 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [09:42<02:03,  5.60s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:51 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:18:54 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [09:48<01:58,  5.65s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:18:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:00 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [09:54<01:54,  5.71s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [10:01<01:53,  5.98s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:12 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:15 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [10:09<01:59,  6.63s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:19 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [10:17<02:01,  7.12s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:27 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [10:24<01:54,  7.17s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:37 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:40 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [10:34<01:57,  7.82s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:43 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [10:40<01:42,  7.35s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [10:47<01:32,  7.15s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:19:56 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:19:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [10:53<01:24,  7.01s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:03 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:06 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [11:00<01:16,  6.98s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:12 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [11:06<01:07,  6.72s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:18 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:20 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [11:15<01:04,  7.17s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:26 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [11:20<00:53,  6.68s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:30 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:32 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [11:26<00:45,  6.57s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:47 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [11:41<00:54,  9.01s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:51 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:20:54 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [11:48<00:41,  8.31s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:20:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:21:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [11:55<00:32,  8.07s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:21:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:21:09 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [12:03<00:24,  8.06s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:21:13 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:21:16 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [12:10<00:15,  7.67s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:21:19 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:21:22 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [12:16<00:07,  7.06s/trial, best loss: 0.11478333007811639]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/31 09:21:25 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n",
      "2024/08/31 09:21:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [12:22<00:00,  7.42s/trial, best loss: 0.11478333007811639]\n"
     ]
    }
   ],
   "source": [
    "# Create a Trials object to store the results of the optimization process\n",
    "trials = Trials()\n",
    "\n",
    "# Start an MLflow experiment\n",
    "with mlflow.start_run(run_name=\"catboost_hyperopt_tuning\"):\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100,\n",
    "        trials=trials\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'bagging_temperature': 0.5447824858171504, 'border_count': 220.0, 'depth': 5.0, 'iterations': 800.0, 'l2_leaf_reg': 13.06135266464145, 'learning_rate': 0.15538685598864, 'one_hot_max_size': 34.0, 'random_strength': 4.115171860221108}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters found:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_temperature': 0.5447824858171504,\n",
       " 'border_count': 220.0,\n",
       " 'depth': 5.0,\n",
       " 'iterations': 800.0,\n",
       " 'l2_leaf_reg': 13.06135266464145,\n",
       " 'learning_rate': 0.15538685598864,\n",
       " 'one_hot_max_size': 34.0,\n",
       " 'random_strength': 4.115171860221108}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 39,\n",
       " 'spec': None,\n",
       " 'result': {'loss': 0.1169679988465582, 'status': 'ok'},\n",
       " 'misc': {'tid': 39,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'bagging_temperature': [39],\n",
       "   'border_count': [39],\n",
       "   'depth': [39],\n",
       "   'iterations': [39],\n",
       "   'l2_leaf_reg': [39],\n",
       "   'learning_rate': [39],\n",
       "   'one_hot_max_size': [39],\n",
       "   'random_strength': [39]},\n",
       "  'vals': {'bagging_temperature': [0.4772142988105587],\n",
       "   'border_count': [200.0],\n",
       "   'depth': [5.0],\n",
       "   'iterations': [450.0],\n",
       "   'l2_leaf_reg': [7.43439511907274],\n",
       "   'learning_rate': [0.22947940228640154],\n",
       "   'one_hot_max_size': [124.0],\n",
       "   'random_strength': [5.316275052028734]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2024, 8, 28, 13, 55, 4, 123000),\n",
       " 'refresh_time': datetime.datetime(2024, 8, 28, 13, 55, 9, 857000)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fc9e5cb19f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CatBoostRegressor(**best_params, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
